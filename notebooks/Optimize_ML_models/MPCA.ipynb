{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA as a fault detection model\n",
    "Multiway-PCA can be used for fault detection when combining it with two types of measurements for errors: The squared prediction error (SPE) and the Hotellings T^2. This notebooks shows how to use the model implemented in this package. Additionaly, gridsearch is performed to find an optimal set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fermfaultdetect.data.utils import load_batchset, dataloader\n",
    "from fermfaultdetect.utils import get_simulation_dir\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from fermfaultdetect.utils import get_models_dir\n",
    "from sklearn.decomposition import PCA\n",
    "from fermfaultdetect.fault_detect_models.ml_models import pca_fdm\n",
    "from fermfaultdetect import model_evaluation as eval\n",
    "from fermfaultdetect.visualizations import visualize\n",
    "from fermfaultdetect.model_evaluation import plot_example_set\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42 # set seeding\n",
    "\n",
    "sim_dir = get_simulation_dir() # get directory of simulation data\n",
    "\n",
    "###############################\n",
    "model_name = \"FILL_IN_MODEL_NAME\" # set the name of model (e.g. date or specific name)\n",
    "train_set_name = \"FILL_IN_TRAINING_SET_NAME\"\n",
    "val_set_name = \"FILL_IN_VALIDATION_SET_NAME\"\n",
    "###############################\n",
    "\n",
    "train_path = os.path.join(sim_dir, train_set_name)\n",
    "val_path = os.path.join(sim_dir, val_set_name)\n",
    "\n",
    "# set directory to save model and metrics\n",
    "model_dir = os.path.join(get_models_dir(), model_name)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "train_set = load_batchset(train_path)\n",
    "val_set = load_batchset(val_path)\n",
    "\n",
    "# Load train data into dataloader and standardize\n",
    "target_cols = ['defect_steambarrier', 'steam_in_feed', 'blocked_spargers', 'airflow_OOC', 'OUR_OOC', 'no_fault'] # set target columns\n",
    "train_dl = dataloader(batchset = train_set[:], seed=seed)\n",
    "train_dl.shuffle_batches()\n",
    "train_dl.standardize_data(exclude_cols=target_cols)\n",
    "\n",
    "# Load test data into dataloader and standardize\n",
    "val_dl = dataloader(batchset = val_set[:], seed=seed)\n",
    "#test_dl.shuffle_batches()\n",
    "val_dl.import_standardization(train_dl)\n",
    "val_dl.standardize_data(exclude_cols=target_cols)\n",
    "\n",
    "# Retrieve data from dataloader with separate and fused target columns\n",
    "train_X, _ = train_dl.get_data(split_batches=False, target_cols=target_cols, separate_target_matrix=True, fuse_target_cols=True)\n",
    "val_X, val_Y = val_dl.get_data(split_batches=False, target_cols=target_cols, separate_target_matrix=True, fuse_target_cols=True)\n",
    "_, val_Y_unfused = val_dl.get_data(split_batches=False, target_cols=target_cols, separate_target_matrix=True, fuse_target_cols=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine number of PCs\n",
    "As a rule of thumb, one should choose a number of PC that explain at least 95 % of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training PCA model\n",
    "pca = PCA()\n",
    "pca.fit(train_X)\n",
    "\n",
    "# Calculating cumulative explained variance\n",
    "cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plotting the cumulative explained variance to determine the number of components to retain\n",
    "colors = visualize.get_thesis_colors()\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(0, len(cumulative_explained_variance)), cumulative_explained_variance, marker='o', color=colors[\"green\"])\n",
    "plt.xlabel('Number of principal components [-]')\n",
    "plt.ylabel('Cumulative explained variance [-]')\n",
    "#plt.title('PCA Cumulative Explained Variance')\n",
    "#plt.grid(True)\n",
    "plt.axhline(y=0.95, color=colors[\"red\"], linestyle='--')  # 95% explained variance line\n",
    "#plt.axhline(y=0.90, color='g', linestyle='--')  # 90% explained variance line\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(model_dir, \"PCA_Cumulative_Explained_Variance.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cumulative_explained_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize detection threshold alpha and moving time window through gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "pc = 3 # choose based on previous section\n",
    "###\n",
    "\n",
    "# Define the range of values for hyperparameters\n",
    "a_values = np.around(np.linspace(0.01, 0.4, 14), 2) #round to 2 decimals\n",
    "mw_values = np.linspace(1, 30, 6, dtype=int)\n",
    "\n",
    "\n",
    "# Set up results list\n",
    "results = []\n",
    "\n",
    "# Loop through all possible combinations of 'a' and 'mw'\n",
    "for a in a_values:\n",
    "    for mw in mw_values:\n",
    "        #accuracy = pca_model_accuracy(train_X, test_X, test_Y, pc=pc, alpha=a, mw=mw)\n",
    "        pca_model = pca_fdm(pc=pc, alpha=a, mw=mw)\n",
    "        pca_model.calibrate(train_X)\n",
    "        accuracy = pca_model.prediction_accuracy(val_X, val_Y)\n",
    "        results.append({\n",
    "            'a': a,\n",
    "            'mw': mw,\n",
    "            'accuracy': accuracy\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Pivot the DataFrame for heatmap plotting\n",
    "pivot_table = results_df.pivot(index='a', columns='mw', values='accuracy')\n",
    "\n",
    "# Save the pivot table to a CSV file\n",
    "heatmap_path = os.path.join(model_dir, \"pca_gridsearch_heatmap_\"+model_name+\".csv\") # can be passed to metrics_table\n",
    "pivot_table.to_csv(heatmap_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print optimal hyperparameters\n",
    "best_row = results_df.loc[results_df['accuracy'].idxmax()]\n",
    "print(f\"Optimal parameters: accuracy = {best_row['accuracy']:.3f}, a = {best_row['a']:.3f}, mw = {best_row['mw']}\")\n",
    "\n",
    "# Plotting the results using seaborn heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.heatmap(pivot_table, annot=False, cmap=visualize.get_hotcold_colormap(), fmt=\".3f\")\n",
    "#plt.title('PCA Model Accuracy Heatmap')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "plt.xlabel(r'Moving time window $\\it{n}$ [-]')\n",
    "plt.ylabel('Threshold Î± [-]')\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(model_dir, \"PCA_Model_Accuracy_Heatmap.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse and save optimal MPCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select optimal threshold and moving window ###\n",
    "alpha = 0.5\n",
    "mw = 1\n",
    "\n",
    "pca_model_best = pca_fdm(pc=3, alpha=best_row['a'], mw=best_row['mw'].astype(int))\n",
    "pca_model_best.calibrate(train_X)\n",
    "predictions_best = pca_model_best.predict(val_X)\n",
    "\n",
    "filepath = os.path.join(model_dir, \"pca_test_opt.csv\")\n",
    "metrics = eval.metrics_table_oneclass(val_Y_unfused, predictions_best[\"fault\"], save_path=filepath)\n",
    "eval.visualize_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PLS model\n",
    "filename = 'model.pkl' # set model name\n",
    "save_path = os.path.join(model_dir, filename)\n",
    "with open(save_path, 'wb') as file:\n",
    "    pickle.dump(pca_model_best, file)\n",
    "\n",
    "# Create and save config\n",
    "config_model = {\n",
    "    \"model\": \"MPCA\",\n",
    "    \"date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"train_set\": train_set_name,\n",
    "    \"name\": model_name,\n",
    "    \"n_components\": pc,\n",
    "    \"alpha\": alpha,\n",
    "    \"moving time window\": mw\n",
    "}\n",
    "\n",
    "# Save the model config as a json file\n",
    "config_name = \"config.json\"\n",
    "config_path = os.path.join(model_dir, config_name)\n",
    "with open(config_path, 'w') as json_file:\n",
    "    json.dump(config_model, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show performance with exemplatory batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_setname = \"FILL_IN_EXAMPLE_SET_NAME\"\n",
    "visualize.set_plot_params(high_res=True)\n",
    "plot_example_set(model=pca_model_best, train_dl=train_dl, setname=example_setname, parameter_plotted=\"weight\", combined_figure=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybmod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
