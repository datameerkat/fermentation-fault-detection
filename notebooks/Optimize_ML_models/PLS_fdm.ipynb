{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLS as a fault detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fermfaultdetect.data.utils import load_batchset, dataloader\n",
    "from fermfaultdetect.utils import get_simulation_dir\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from fermfaultdetect.utils import get_models_dir\n",
    "from fermfaultdetect.visualizations import visualize\n",
    "from fermfaultdetect.fault_detect_models.ml_models import pls_fdm\n",
    "from fermfaultdetect import model_evaluation as eval\n",
    "from fermfaultdetect.model_evaluation import plot_example_set\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42 # set seeding\n",
    "\n",
    "sim_dir = get_simulation_dir() # get directory of simulation data\n",
    "\n",
    "##############################################\n",
    "model_name = \"FILL_IN_MODEL_NAME\" # set the name of model (e.g. date or specific name)\n",
    "train_set_name = \"FILL_IN_TRAINING_SET_NAME\"\n",
    "val_set_name = \"FILL_IN_VALIDATION_SET_NAME\"\n",
    "##############################################\n",
    "\n",
    "train_path = os.path.join(sim_dir, train_set_name)\n",
    "val_path = os.path.join(sim_dir, val_set_name)\n",
    "\n",
    "# set directory to save model and metrics\n",
    "model_dir = os.path.join(get_models_dir(), model_name)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "train_set = load_batchset(train_path)\n",
    "val_set = load_batchset(val_path)\n",
    "\n",
    "# Load train data into dataloader and standardize\n",
    "target_cols = ['defect_steambarrier', 'steam_in_feed', 'blocked_spargers', 'airflow_OOC', 'OUR_OOC', 'no_fault'] # set target columns\n",
    "train_dl = dataloader(batchset = train_set[:], seed=seed)\n",
    "train_dl.shuffle_batches()\n",
    "train_dl.standardize_data(exclude_cols=target_cols)\n",
    "\n",
    "# Load test data into dataloader and standardize\n",
    "val_dl = dataloader(batchset = val_set[:], seed=seed)\n",
    "val_dl.import_standardization(train_dl)\n",
    "val_dl.standardize_data(exclude_cols=target_cols)\n",
    "\n",
    "# Retrieve data from dataloader with separate and fused target columns\n",
    "train_X, train_Y = train_dl.get_data(split_batches=False, target_cols=target_cols, separate_target_matrix=True, fuse_target_cols=True)\n",
    "val_X, val_Y = val_dl.get_data(split_batches=False, target_cols=target_cols, separate_target_matrix=True, fuse_target_cols=True)\n",
    "_, val_Y_unfused = val_dl.get_data(split_batches=False, target_cols=target_cols, separate_target_matrix=True, fuse_target_cols=False)\n",
    "\n",
    "# Cut target column to 1D-array\n",
    "train_Y = train_Y[[\"fault\"]]\n",
    "val_Y = val_Y[[\"fault\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize components, detection threshold tau and moving time window through gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of values for hyperparameters\n",
    "th_values = np.round(np.linspace(0.2, 0.8, 13), decimals=2)\n",
    "mw_values = np.linspace(1, 30, 6, dtype=int)\n",
    "pc_values = np.arange(1,8)\n",
    "\n",
    "# Prepare to collect results\n",
    "results = []\n",
    "best_model = None\n",
    "\n",
    "# Loop through all possible combinations of 'th' and 'mw'\n",
    "for pc in pc_values:\n",
    "    for mw in mw_values:\n",
    "        for th in th_values:\n",
    "            pls_model = pls_fdm(n_components=pc, threshold=th, mw=mw)\n",
    "            pls_model.train(train_X, train_Y)\n",
    "            accuracy = pls_model.prediction_accuracy(val_X, val_Y)\n",
    "            results.append({\n",
    "                'th': th,\n",
    "                'mw': mw,\n",
    "                'pc': pc,\n",
    "                'accuracy': accuracy\n",
    "            })\n",
    "            if best_model is None or accuracy > best_model['accuracy']:\n",
    "                best_model = {\n",
    "                    'th': th,\n",
    "                    'mw': mw,\n",
    "                    'pc': pc,\n",
    "                    'accuracy': accuracy\n",
    "                }\n",
    "    print(f\"Finished with {pc} components\")\n",
    "\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Choose results with optimal n_components\n",
    "best_pc_results = results_df[results_df['pc'] == best_model['pc']]\n",
    "\n",
    "# Pivot the DataFrame for heatmap plotting\n",
    "pivot_table = best_pc_results.pivot(index='th', columns='mw', values='accuracy')\n",
    "\n",
    "# Save the pivot table to a CSV file\n",
    "heatmap_path = os.path.join(model_dir, \"pls_gridsearch_heatmap_\"+model_name+\".csv\") # can be passed to metrics_table\n",
    "pivot_table.to_csv(heatmap_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print optimal hyperparameters\n",
    "best_row = results_df.loc[results_df['accuracy'].idxmax()]\n",
    "print(f\"Optimal parameters: accuracy = {best_row['accuracy']:.3f}, threshold = {best_row['th']:.3f}, moving time window = {best_row['mw']}\")\n",
    "\n",
    "# Plotting the results using seaborn heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "visualize.set_plot_params(high_res=True)\n",
    "ax = sns.heatmap(pivot_table, annot=False, cmap=visualize.get_hotcold_colormap(), fmt=\".3f\")\n",
    "#plt.title('PLS Model Accuracy Heatmap')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "plt.xlabel(r'Moving time window $\\it{n}$ [-]')\n",
    "plt.ylabel('Threshold Ï„ [-]')\n",
    "# Save the heatmap\n",
    "plt.savefig(os.path.join(model_dir, \"pls_gridsearch_heatmap_\"+model_name+\".png\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse and save optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_model_best = pls_fdm(n_components=best_row['pc'].astype(int), threshold=best_row['th'], mw=best_row['mw'].astype(int))\n",
    "pls_model_best.train(train_X, train_Y)\n",
    "predictions_best = pls_model_best.predict(val_X)\n",
    "\n",
    "metrics_path = os.path.join(model_dir, \"pls_metrics_opt_\"+model_name+\".csv\")\n",
    "metrics = eval.metrics_table_oneclass(val_Y_unfused, predictions_best[\"fault\"], save_path=metrics_path)\n",
    "eval.visualize_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PLS model\n",
    "filename = 'model.pkl' # set model name\n",
    "save_path = os.path.join(model_dir, filename)\n",
    "pls_model_best.clear_large_attributes() # clear large attributes before saving\n",
    "with open(save_path, 'wb') as file:\n",
    "    pickle.dump(pls_model_best, file)\n",
    "\n",
    "\n",
    "# Create and save config\n",
    "config_model = {\n",
    "    \"model\": \"PLS-DA\",\n",
    "    \"date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"train_set\": train_set_name,\n",
    "    \"name\": model_name,\n",
    "    \"n_components\": best_row['pc'],\n",
    "    \"threshold\": best_row['th'],\n",
    "    \"moving time window\": best_row['mw']\n",
    "}\n",
    "\n",
    "# Save the model config as a json file\n",
    "config_name = \"config.json\"\n",
    "config_path = os.path.join(model_dir, config_name)\n",
    "with open(config_path, 'w') as json_file:\n",
    "    json.dump(config_model, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show performance with exemplatory validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_setname = \"FILL_IN_EXAMPLE_SET_NAME\"\n",
    "plot_example_set(model=pls_model_best, dataset_name=example_setname, parameter_plotted=\"weight\", combined_figure=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybmod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
